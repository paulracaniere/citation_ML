{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import AllGraphFunctions as GF\n",
    "import OtherFeaturesFunctions as FF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'float'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "#with open(\"testing_set.txt\", \"r\") as f:\n",
    "#    reader = csv.reader(f)\n",
    "#    testing_set  = list(reader)\n",
    "\n",
    "testing_set = np.array(pd.read_csv(\"./testing_set.txt\", delimiter=' ', header=None))\n",
    "training_set = np.array(pd.read_csv(\"./training_set.txt\", delimiter=' ', header=None))\n",
    "#print(testing_set)\n",
    "\n",
    "#testing_set = [element[0].split(\" \") for element in testing_set]\n",
    "\n",
    "#with open(\"training_set.txt\", \"r\") as f:\n",
    "#    reader = csv.reader(f)\n",
    "#    training_set  = list(reader)\n",
    "\n",
    "#training_set = [element[0].split(\" \") for element in training_set]\n",
    "\n",
    "node_info = pd.read_csv(\"./node_information.csv\")\n",
    "node_info.fillna('')\n",
    "node_info = np.array(node_info)\n",
    "print(type(node_info[16827,3]))\n",
    "\n",
    "IDs = [element[0] for element in node_info]\n",
    "\n",
    "print(node_info[16827,3] != node_info[16827,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_set_paul = np.array(pd.read_csv(\"paul_my_train.csv\").values)\n",
    "testing_set_paul = np.array(pd.read_csv(\"paul_my_test.csv\").values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "G = GF.graph_articles(training_set, node_info, directed_or_not = 'y')\n",
    "#Gauth = GF.graph_authors(training_set, node_info, IDs)\n",
    "#Gauthw = GF.graph_authors_weight(training_set, node_info, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\kingr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kingr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "stpwds, stemmer = FF.initialize_nltk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "citation_set = testing_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "author_affinity = FF.compute_author_affinity(citation_set, node_info, Gauthw,IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'training examples processsed')\n",
      "(5001, 'training examples processsed')\n",
      "(10001, 'training examples processsed')\n",
      "(15001, 'training examples processsed')\n",
      "(20001, 'training examples processsed')\n",
      "(25001, 'training examples processsed')\n",
      "(30001, 'training examples processsed')\n",
      "(35001, 'training examples processsed')\n",
      "(40001, 'training examples processsed')\n",
      "(45001, 'training examples processsed')\n",
      "(50001, 'training examples processsed')\n",
      "(55001, 'training examples processsed')\n",
      "(60001, 'training examples processsed')\n",
      "(65001, 'training examples processsed')\n",
      "(70001, 'training examples processsed')\n",
      "(75001, 'training examples processsed')\n",
      "(80001, 'training examples processsed')\n",
      "(85001, 'training examples processsed')\n",
      "(90001, 'training examples processsed')\n",
      "(95001, 'training examples processsed')\n",
      "(100001, 'training examples processsed')\n",
      "(105001, 'training examples processsed')\n",
      "(110001, 'training examples processsed')\n",
      "(115001, 'training examples processsed')\n",
      "(120001, 'training examples processsed')\n",
      "(125001, 'training examples processsed')\n",
      "(130001, 'training examples processsed')\n",
      "(135001, 'training examples processsed')\n",
      "(140001, 'training examples processsed')\n",
      "(145001, 'training examples processsed')\n",
      "(150001, 'training examples processsed')\n",
      "(155001, 'training examples processsed')\n",
      "(160001, 'training examples processsed')\n",
      "(165001, 'training examples processsed')\n",
      "(170001, 'training examples processsed')\n",
      "(175001, 'training examples processsed')\n",
      "(180001, 'training examples processsed')\n",
      "(185001, 'training examples processsed')\n",
      "(190001, 'training examples processsed')\n",
      "(195001, 'training examples processsed')\n",
      "(200001, 'training examples processsed')\n",
      "(205001, 'training examples processsed')\n",
      "(210001, 'training examples processsed')\n",
      "(215001, 'training examples processsed')\n",
      "(220001, 'training examples processsed')\n",
      "(225001, 'training examples processsed')\n",
      "(230001, 'training examples processsed')\n",
      "(235001, 'training examples processsed')\n",
      "(240001, 'training examples processsed')\n",
      "(245001, 'training examples processsed')\n",
      "(250001, 'training examples processsed')\n",
      "(255001, 'training examples processsed')\n",
      "(260001, 'training examples processsed')\n",
      "(265001, 'training examples processsed')\n",
      "(270001, 'training examples processsed')\n",
      "(275001, 'training examples processsed')\n",
      "(280001, 'training examples processsed')\n",
      "(285001, 'training examples processsed')\n",
      "(290001, 'training examples processsed')\n",
      "(295001, 'training examples processsed')\n",
      "(300001, 'training examples processsed')\n",
      "(305001, 'training examples processsed')\n",
      "(310001, 'training examples processsed')\n",
      "(315001, 'training examples processsed')\n",
      "(320001, 'training examples processsed')\n",
      "(325001, 'training examples processsed')\n",
      "(330001, 'training examples processsed')\n",
      "(335001, 'training examples processsed')\n",
      "(340001, 'training examples processsed')\n",
      "(345001, 'training examples processsed')\n",
      "(350001, 'training examples processsed')\n",
      "(355001, 'training examples processsed')\n",
      "(360001, 'training examples processsed')\n",
      "(365001, 'training examples processsed')\n",
      "(370001, 'training examples processsed')\n",
      "(375001, 'training examples processsed')\n",
      "(380001, 'training examples processsed')\n",
      "(385001, 'training examples processsed')\n",
      "(390001, 'training examples processsed')\n",
      "(395001, 'training examples processsed')\n",
      "(400001, 'training examples processsed')\n",
      "(405001, 'training examples processsed')\n",
      "(410001, 'training examples processsed')\n",
      "(415001, 'training examples processsed')\n",
      "(420001, 'training examples processsed')\n",
      "(425001, 'training examples processsed')\n",
      "(430001, 'training examples processsed')\n",
      "(435001, 'training examples processsed')\n",
      "(440001, 'training examples processsed')\n",
      "(445001, 'training examples processsed')\n",
      "(450001, 'training examples processsed')\n",
      "(455001, 'training examples processsed')\n",
      "(460001, 'training examples processsed')\n",
      "(465001, 'training examples processsed')\n",
      "(470001, 'training examples processsed')\n",
      "(475001, 'training examples processsed')\n",
      "(480001, 'training examples processsed')\n",
      "(485001, 'training examples processsed')\n",
      "(490001, 'training examples processsed')\n"
     ]
    }
   ],
   "source": [
    "Journal = FF.compute_same_journal_or_not(citation_set, node_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'training examples processsed')\n",
      "(5001, 'training examples processsed')\n",
      "(10001, 'training examples processsed')\n",
      "(15001, 'training examples processsed')\n",
      "(20001, 'training examples processsed')\n",
      "(25001, 'training examples processsed')\n",
      "(30001, 'training examples processsed')\n"
     ]
    }
   ],
   "source": [
    "TFIDF_abstract = FF.compute_TFIDF_abstract_feature(citation_set, node_info,IDs, stpwds, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'training examples processsed')\n",
      "(5001, 'training examples processsed')\n",
      "(10001, 'training examples processsed')\n",
      "(15001, 'training examples processsed')\n",
      "(20001, 'training examples processsed')\n",
      "(25001, 'training examples processsed')\n",
      "(30001, 'training examples processsed')\n"
     ]
    }
   ],
   "source": [
    "TFIDF_title = FF.compute_TFIDF_title_feature(citation_set, node_info, IDs, stpwds, stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'training examples processsed')\n",
      "(5001, 'training examples processsed')\n",
      "(10001, 'training examples processsed')\n",
      "(15001, 'training examples processsed')\n",
      "(20001, 'training examples processsed')\n",
      "(25001, 'training examples processsed')\n",
      "(30001, 'training examples processsed')\n"
     ]
    }
   ],
   "source": [
    "Time_difference = FF.compute_temp_diff(citation_set, node_info, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'training examples processsed')\n",
      "(5001, 'training examples processsed')\n",
      "(10001, 'training examples processsed')\n",
      "(15001, 'training examples processsed')\n",
      "(20001, 'training examples processsed')\n",
      "(25001, 'training examples processsed')\n",
      "(30001, 'training examples processsed')\n"
     ]
    }
   ],
   "source": [
    "overlapping_titles = FF.compute_overlaping_titles(citation_set, node_info, IDs, stemmer, stpwds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 'training examples processsed')\n",
      "(5001, 'training examples processsed')\n",
      "(10001, 'training examples processsed')\n",
      "(15001, 'training examples processsed')\n",
      "(20001, 'training examples processsed')\n",
      "(25001, 'training examples processsed')\n",
      "(30001, 'training examples processsed')\n"
     ]
    }
   ],
   "source": [
    "number_of_common_auth = FF.compute_common_auth(citation_set, node_info, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_index = FF.h_index(citation_set, node_info, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# bug sur la première valeur\n",
    "articles_page_rank = FF.articles_page_rank_feature(citation_set, node_info, G, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "authors_page_rank = FF.authors_page_rank_feature(citation_set, node_info, Gauth, IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# renvoie un array 27 000 au lieu de 1000\n",
    "page_club = FF.page_club_feature(citation_set, node_info, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-6657e381905e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# bug sur la première valeur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mshorthest_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshorthest_path_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\kingr\\Github\\citation_ML\\OtherFeaturesFunctions.py\u001b[0m in \u001b[0;36mshorthest_path_feature\u001b[1;34m(citation_set, node_info, G)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshorthest_path_feature\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mGF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_shorthest_path_feature_for_articles\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation_set\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcompute_author_affinity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation_set\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIDs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Github\\citation_ML\\AllGraphFunctions.pyc\u001b[0m in \u001b[0;36mcompute_shorthest_path_feature_for_articles\u001b[1;34m(citation_set, G)\u001b[0m\n\u001b[0;32m    415\u001b[0m             \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove_edge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m         sht_pth_features.append(\n\u001b[1;32m--> 417\u001b[1;33m                 nx.shortest_path_length(G,citation[0], citation[1]) if nx.has_path(G, citation[0], citation[1]) else 30)\n\u001b[0m\u001b[0;32m    418\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'1'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    419\u001b[0m             \u001b[0mG\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_edge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.pyc\u001b[0m in \u001b[0;36mhas_path\u001b[1;34m(G, source, target)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \"\"\"\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         \u001b[0msp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshortest_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     41\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNetworkXNoPath\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\generic.pyc\u001b[0m in \u001b[0;36mshortest_path\u001b[1;34m(G, source, target, weight)\u001b[0m\n\u001b[0;32m    140\u001b[0m             \u001b[1;31m# Find shortest source-target path.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m                 \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbidirectional_shortest_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m                 \u001b[0mpaths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdijkstra_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.pyc\u001b[0m in \u001b[0;36mbidirectional_shortest_path\u001b[1;34m(G, source, target)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m     \u001b[1;31m# call helper to do the real work\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 226\u001b[1;33m     \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_bidirectional_pred_succ\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    227\u001b[0m     \u001b[0mpred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msucc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\networkx\\algorithms\\shortest_paths\\unweighted.pyc\u001b[0m in \u001b[0;36m_bidirectional_pred_succ\u001b[1;34m(G, source, target)\u001b[0m\n\u001b[0;32m    275\u001b[0m             \u001b[0mforward_fringe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    276\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthis_level\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mGsucc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    278\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m                         \u001b[0mforward_fringe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\networkx\\classes\\coreviews.pyc\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mAtlasView\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_atlas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# bug sur la première valeur\n",
    "shorthest_path = FF.shorthest_path_feature(citation_set, node_info, G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.542293921505719, 2.451104943996727, 2.0148614734563193, 4.167122451960857, 2.257231576716985, 2.063804839464347, 2.8279064514184915, 2.425135817609566, 2.5892779281180083, 2.0261594782086947]\n"
     ]
    }
   ],
   "source": [
    "print(page_club[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\gensim\\models\\doc2vec.py:366: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4b59ecabaf9c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtitle_doc2voc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle_doc2voc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_info\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcitation_set\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\kingr\\Github\\citation_ML\\OtherFeaturesFunctions.pyc\u001b[0m in \u001b[0;36mtitle_doc2voc\u001b[1;34m(node_info, citation_set)\u001b[0m\n\u001b[0;32m     43\u001b[0m         model_title.train(token_title,\n\u001b[0;32m     44\u001b[0m                     \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m                     epochs=model_title.iter)\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m         \u001b[0mmodel_title\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m0.0002\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\gensim\\models\\doc2vec.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, documents, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, callbacks)\u001b[0m\n\u001b[0;32m    510\u001b[0m             \u001b[0mdocuments\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 512\u001b[1;33m             queue_factor=queue_factor, report_delay=report_delay, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    514\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_raw_word_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\gensim\\models\\base_any2vec.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, sentences, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[0;32m    567\u001b[0m             \u001b[0msentences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 569\u001b[1;33m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[0;32m    570\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\gensim\\models\\base_any2vec.pyc\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data_iterable, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    255\u001b[0m             trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[0;32m    256\u001b[0m                 \u001b[0mdata_iterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                 queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[0;32m    258\u001b[0m             \u001b[0mtrained_word_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mtrained_word_count_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[0mraw_word_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mraw_word_count_epoch\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\gensim\\models\\base_any2vec.pyc\u001b[0m in \u001b[0;36m_train_epoch\u001b[1;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[0;32m    225\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[0;32m    226\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m             report_delay=report_delay)\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\site-packages\\gensim\\models\\base_any2vec.pyc\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[1;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay)\u001b[0m\n\u001b[0;32m    173\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    174\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 175\u001b[1;33m             \u001b[0mreport\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# blocks if workers too slow\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    176\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# a thread reporting that it finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    177\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\Queue.pyc\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    166\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m                 \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\kingr\\Anaconda2\\lib\\threading.pyc\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    338\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 340\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    341\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0m__debug__\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    342\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_note\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s.wait(): got it\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "title_doc2voc = FF.title_doc2voc(node_info, citation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "abstract_doc2voc = FF.abstract_doc2voc(node_info, citation_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "col = ['feature_TFIDF_abstract',\n",
    "      'feature_TFIDF_title',\n",
    "      'feature_time_difference',\n",
    "      'feature_overlapping_title',\n",
    "      'feature_common_author',\n",
    "      'feature_h_index',\n",
    "      'feature_articles_page_rank'\n",
    "      'feature_author_page_rank',\n",
    "      'feature_page_club',\n",
    "      'feature_author_affinity',\n",
    "      'feature_journal']\n",
    "#data_array = np.array([TFIDF_abstract,\n",
    "#                TFIDF_title,\n",
    "#                Time_difference,\n",
    "#                overlapping_titles,\n",
    "#                number_of_common_auth,\n",
    "#                h_index,\n",
    "#                articles_page_rank,\n",
    "#                authors_page_rank,\n",
    "#                page_club,\n",
    "#                author_affinity[:len(page_club)],\n",
    "#                Journal])\n",
    "data_array = np.array([\n",
    "                author_affinity])\n",
    "data_array = np.transpose(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# créer un dataframe avec toutes les données\n",
    "data = pd.DataFrame(data_array)\n",
    "\n",
    "# écris le dataframe en csv avec toutes les données dans le répertoire actuel\n",
    "data.to_csv('author_affinity_test_sample.csv', index=0)\n",
    "\n",
    "# lis un fichier csv\n",
    "data_bis = pd.read_csv('author_affinity_test_sample.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 8.88500256e-02  7.38240074e-02  0.00000000e+00 ...  2.08048599e+00\n",
      "   0.00000000e+00  0.00000000e+00]\n",
      " [ 1.86552695e-01  3.36193955e-01  1.00000000e+00 ...  4.36701750e+00\n",
      "   6.20000000e+01  0.00000000e+00]\n",
      " [ 1.39150107e-01  1.56634973e-01  2.00000000e+00 ...  2.88269148e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " ...\n",
      " [ 4.37584261e-02  0.00000000e+00  4.00000000e+00 ...  2.02240746e+00\n",
      "   1.40000000e+01  0.00000000e+00]\n",
      " [ 7.87700867e-03  0.00000000e+00 -7.00000000e+00 ...  2.15499053e+00\n",
      "   0.00000000e+00  1.00000000e+00]\n",
      " [ 5.27698869e-02  0.00000000e+00  2.00000000e+00 ...  3.09111528e+00\n",
      "   0.00000000e+00  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(data_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_TFIDF_abstract</th>\n",
       "      <th>feature_TFIDF_title</th>\n",
       "      <th>feature_time_difference</th>\n",
       "      <th>feature_overlapping_title</th>\n",
       "      <th>feature_common_author</th>\n",
       "      <th>feature_author_page_rank</th>\n",
       "      <th>feature_author_affinity</th>\n",
       "      <th>feature_journal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.349091</td>\n",
       "      <td>1.290807</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.038647</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.383222</td>\n",
       "      <td>1.414214</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_TFIDF_abstract  feature_TFIDF_title  feature_time_difference  \\\n",
       "0                1.349091             1.290807                      0.0   \n",
       "1                1.383222             1.414214                      1.0   \n",
       "\n",
       "   feature_overlapping_title  feature_common_author  feature_author_page_rank  \\\n",
       "0                        2.0                    0.0                  0.038647   \n",
       "1                        1.0                    0.0                  0.001800   \n",
       "\n",
       "   feature_author_affinity  feature_journal  \n",
       "0                      3.0              1.0  \n",
       "1                      4.0              0.0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ça montre les deux premières lignes\n",
    "data_bis.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.34909131, 1.29080743, 0.        , 2.        , 0.        ,\n",
       "       0.03864696, 3.        , 1.        ])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# avoir accès à la matrce des features, ici la première ligne\n",
    "data_bis.values[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
